---
- name: Lustre setup
  hosts: lustre, lustre-oss-*, robinhood
  become: true
  vars_files:
    - '{{global_config_file}}'

  tasks:
  - name: Disable SELinux
    selinux:
      state: disabled
    register: selinux
  - name: reboot 
    reboot:
    when: selinux.reboot_required 
  - name: Add Lustre server repo
    yum_repository:
      name: lustreserver
      description: Lustre repo
      baseurl: https://downloads.whamcloud.com/public/lustre/lustre-{{ lustre.version }}/el7/patchless-ldiskfs-server/
      file: LustrePack
      enabled: yes
      gpgcheck: no
  - name: Add Lustre client repo
    yum_repository:
      name: lustreclient
      description: Lustre repo
      baseurl: https://downloads.whamcloud.com/public/lustre/lustre-{{ lustre.version }}/el7/client/
      file: LustrePack
      enabled: yes
      gpgcheck: no
  - name: Add e2fs repo
    yum_repository:
      name: e2fs
      description: Lustre repo
      baseurl: https://downloads.whamcloud.com/public/e2fsprogs/latest/el7/
      file: LustrePack
      enabled: yes
      gpgcheck: no
  - name: Install lustre packages
    yum:
      name:
        - lustre
        - kmod-lustre-osd-ldiskfs
        - lustre-osd-ldiskfs-mount
        - lustre-resource-agents
        - e2fsprogs
        - lustre-tests
      state: present
    register: install_rpms
  - name: disable resource disk
    lineinfile: 
      path: /etc/waagent.conf 
      regexp: '^ResourceDisk\.Format=y$' 
      line: 'ResourceDisk.Format=n'
      backrefs: yes
    register: disable_resource_disk
  - name: restart waagent if config changed
    service:
      name: waagent
      state: restarted
    when: disable_resource_disk.changed
  - name: ensure temp-disk-swapdile is stopped
    service:
      name: temp-disk-swapfile
      state: stopped
  - name: run weak-modules
    command: weak-modules --add-kernel --no-initramfs
    when: install_rpms.changed
  - name: ensure resource disk is not mounted
    mount:
      path: /mnt/resource
      state: unmounted

- name: Lustre MDS setup
  hosts: lustre
  become: true
  vars_files:
    - '{{global_config_file}}'
  
  tasks:
  - name: get mdt device info
    command: lsblk -f {{ lustre.mdt_device }}
    changed_when: false
    register: lsblk_mdt
  - name: format mdt
    shell: >
      mkfs.lustre 
      --fsname=LustreFS --mgs --mdt
      --mountfsoptions="user_xattr,errors=remount-ro"
      --backfstype=ldiskfs
      --reformat {{ lustre.mdt_device }}
      --index 0
    when: not lsblk_mdt.stdout is search('LustreFS')
  - name: create mdt mount directory
    file:
      path: /mnt/mgsmds
      state: directory
  - name: mount mdt
    mount:
      path: /mnt/mgsmds
      src: '{{ lustre.mdt_device }}'
      opts: noatime,nodiratime,nobarrier
      passno: '2'
      state: mounted
      fstype: lustre
  - name: set mdt params
    shell: |
      lctl set_param -P mdt.*-MDT0000.hsm_control=enabled
      lctl set_param -P mdt.*-MDT0000.hsm.default_archive_id=1
      lctl set_param mdt.*-MDT0000.hsm.max_requests={{ lustre.hsm_max_requests }}
      lctl set_param mdt.*-MDT0000.identity_upcall=NONE

- name: Lustre OSS setup
  hosts: lustre-oss-*
  become: true
  vars_files:
    - '{{global_config_file}}'
  
  tasks:
  - name: get ost device info
    command: lsblk -f {{ lustre.ost_device }}
    changed_when: false
    register: lsblk_ost
  - name: get ost index
    shell: hostname | sed 's/lustre-oss-//g'
    changed_when: false
    register: ost_index
  - name: format ost
    shell: >
      mkfs.lustre 
      --fsname=LustreFS
      --backfstype=ldiskfs
      --reformat
      --ost
      --mgsnode=lustre
      --index={{ ost_index.stdout }}
      --mountfsoptions="errors=remount-ro"
      {{ lustre.ost_device }}
    when: not lsblk_ost.stdout is search('LustreFS')
  - name: create ost mount directory
    file:
      path: /mnt/oss
      state: directory
  - name: mount ost
    mount:
      path: /mnt/oss
      src: '{{ lustre.ost_device }}'
      opts: noatime,nodiratime,nobarrier
      passno: '2'
      state: mounted
      fstype: lustre

- name: Lustre HSM setup
  hosts: lustre-oss-*
  become: true
  vars_files:
    - '{{global_config_file}}'
  
  tasks:
  - name: install hsm rpms
    yum:
      name:
        - https://azurehpc.azureedge.net/rpms/lemur-azure-hsm-agent-1.0.0_28_centos77_fileidfix.x86_64.rpm
        - https://azurehpc.azureedge.net/rpms/lemur-azure-data-movers-1.0.0_28_centos77_fileidfix.x86_64.rpm
      state: present
  - name: create var/run/lhsmd
    file: 
      path: /var/run/lhsmd
      state: directory
      mode: 0755
  - name: create /etc/lhsmd
    file: 
      path: /etc/lhsmd
      state: directory
      mode: 0755
  - name: create agent config
    copy:
      dest: /etc/lhsmd/agent
      mode: 0600
      content: |
        client_device="lustre@tcp:/LustreFS"
        enabled_plugins=["lhsm-plugin-az"]
        plugin_dir="/usr/libexec/lhsmd"
        handler_count=16
        snapshots {
          enabled = false
        }
  - name: create lhsm-plugin-az config
    copy:
      dest: /etc/lhsmd/lhsm-plugin-az
      mode: 0600
      content: |
        num_threads=128
        az_storage_account="{{ lustre.hsm.storage_account }}"
        az_kv_name="{{ lustre.hsm.keyvault_name }}"
        az_kv_secret_name="{{ lustre.hsm.keyvault_secret }}"
        region="westeurope"
        bandwidth=0
        exportprefix=""
        archive "archive1" {
            id=1
            num_threads=128
            root=""
            compression="off"
            container="{{ lustre.hsm.storage_container }}"
            region="westeurope"
        }
  - name: create lhsmd service
    copy:
      dest: /etc/systemd/system/lhsmd.service
      mode: 0600
      content: |
        [Unit]
        Description=The lhsmd server
        After=syslog.target network.target remote-fs.target nss-lookup.target
        [Service]
        Type=simple
        PIDFile=/run/lhsmd.pid
        ExecStartPre=/bin/mkdir -p /var/run/lhsmd
        ExecStart=/sbin/lhsmd -config /etc/lhsmd/agent
        Restart=always
        [Install]
        WantedBy=multi-user.target
  - name: systemd daemon reload
    systemd:
      daemon_reload: yes
  - name: enable and start lhsmd service
    service:
      name: lhsmd
      enabled: yes
      state: started
  
- name: Lustre client setup
  hosts: robinhood
  become: true
  vars_files:
    - '{{global_config_file}}'
  
  tasks:  
  - name: create lustre mount directory
    file:
      path: /lustre
      state: directory
  - name: mount lustre
    mount:
      path: /lustre
      src: lustre@tcp0:/LustreFS
      opts: flock,defaults,_netdev
      state: mounted
      fstype: lustre

- name: Install hydrator
  hosts: robinhood
  become: true
  vars_files:
    - '{{global_config_file}}'
  
  tasks:
  - name: check for python 3.7
    stat:
      path: /usr/local/bin/python3.7
    register: stat_python_result
  - name: install python 3.7
    shell: |
      export PATH=/usr/local/bin:$PATH
      # install python 3.7
      yum -y install git gcc openssl-devel bzip2-devel libffi-devel zlib-devel
      cd /usr/src
      wget https://www.python.org/ftp/python/3.7.9/Python-3.7.9.tgz
      tar xzf Python-3.7.9.tgz
      cd Python-3.7.9
      ./configure --enable-optimizations
      make altinstall
    when: not stat_python_result.stat.exists
  - name: check for hydrator
    stat:
      path: /opt/amlFilesystem-hydrator/laaso/hydrator.py
    register: stat_hydrator
  - name: install lustre hydrator
    shell: |
      export PATH=/usr/local/bin:$PATH
      # set up hydrator
      pip3.7 install virtualenv
      cd /opt
      git clone https://github.com/microsoft/amlFilesystem-hydrator.git
      cd amlFilesystem-hydrator/
      git checkout 5d7818165feb0ff2dfd1bb10e964670900e75ed6
      python3.7 -m venv venv
      rm -rf venv
      python3.7 build/venv_create.py venv laaso/requirements.txt
    when: not stat_hydrator.stat.exists
  - name: check to see if lustre is hydrated
    stat:
      path: /lustre.hydrated
    register: stat_hydrated
  - name: hydrate lustre
    shell: |
      export PATH=/usr/local/bin:$PATH
      cd /opt/amlFilesystem-hydrator
      VENV=$(pwd)/venv
      REPO_DIR=.
      source $VENV/bin/activate
      PYTHONPATH=. python3.7 laaso/hydrator.py "{{ lustre.hsm.storage_account }}" "{{ lustre.hsm.storage_container }}" "{{ lustre.hsm.storage_sas }}" -a /lustre --lemur
      touch /lustre.hydrated
    when: not stat_hydrated.stat.exists