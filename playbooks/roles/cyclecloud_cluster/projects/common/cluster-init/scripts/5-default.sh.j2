#!/bin/bash
# Pre-requisites:
# - jq installed
script_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
source "$script_dir/../files/azhop-helpers.sh" 
read_os

# Apply default configuration to the node
# Remote read access to the cluster init script files for all users
chmod 700 -R /mnt/cluster-init

# change access to resource so that temp jobs can be written there
# on Ubuntu and AlmaLinux resource disk is mounted in /mnt
[ -d /mnt/resource ] || mkdir /mnt/resource
chmod 777 /mnt/resource

# Fix slurm compatibility issue with Ubuntu 18.04
# slurmd binary expects 'su' in /usr/bin
[ -e /usr/bin/su ] || ln -s /bin/su /usr/bin/su

# For any NV instances, reinit the session
VM_SIZE=$(curl -s --noproxy "*" -H Metadata:true "http://169.254.169.254/metadata/instance/compute?api-version=2019-08-15" | jq -r '.vmSize' | tr '[:upper:]' '[:lower:]' | sed 's/standard_//')
case $VM_SIZE in
  nv*|nc*t4_v3)
    echo "Configure xorg.conf"
    nvidia-xconfig --enable-all-gpus --allow-empty-initial-configuration -c /etc/X11/xorg.conf --virtual=1920x1200 -s
    sed -i '/Section "Device"/a\    Option         "HardDPMS" "false"' /etc/X11/xorg.conf
    echo "Enabling GUI"
    systemctl restart gdm
    
    if [ -e $script_dir/../files/$os_release/fix_websockify.sh ]; then
      $script_dir/../files/$os_release/fix_websockify.sh
    fi
  ;;
esac

# Create a symlink for the Modules to allow compatibility with the HPC CentOS image which have Modules in capital case
if [ ! -d /usr/share/Modules ]; then
    ln -s /usr/share/modules /usr/share/Modules
fi

# Add modulefiles from HPC CentOS image to module path
export MODULEPATH=$MODULEPATH:/usr/share/Modules/modulefiles/

# Disable the antivirus
if [ -a /usr/lib/systemd/system/azsecd.service ] ; then
  systemctl stop azsecd
  systemctl disable azsecd
  echo "Disabled azsecd service"
fi

