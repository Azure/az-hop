---
- name: Perform OS dependent configuration tasks
  include_tasks: "{{ansible_distribution}}/jetpack.yml"

- name: fix jetpack permissions
  file:
    path: '{{jetpack_home}}'
    mode: u=rwX,g=rX,o=rX
    recurse: yes

- name: create jetpack.ini file
  template:
    src: templates/jetpack.ini.j2
    dest: '{{jetpack_home}}/config/jetpack.ini'
    mode: 0700

- name: Read database Password from KV
  command: az keyvault secret show --vault-name {{key_vault}} -n {{database_user}}-password --query "value" -o tsv
  delegate_to: localhost
  connection: local
  register: database_password_out
  become: false
  when: slurm.accounting_enabled | default(false)

- name: create scheduler node info
  template:
    src: templates/node.json.j2
    dest: '{{jetpack_home}}/config/node.json'
    mode: 0700
  vars:
    database_password: "{{database_password_out.stdout | default('')}}"

# Install slurm. 
# For reference see https://github.com/Azure/cyclecloud-slurm/blob/master/specs/scheduler/cluster-init/scripts/00-install.sh
- name: Download and extract {{install_pkg}}
  unarchive:
    src: https://github.com/Azure/cyclecloud-slurm/releases/download/{{cyclecloud_slurm_release}}/{{install_pkg}}
    dest: '{{jetpack_home}}/system/bootstrap'
    remote_src: yes
  args: 
    creates: '{{jetpack_home}}/system/bootstrap/{{install_pkg}}'
    
- name: install azure-slurm-install
  shell: |
    set -e
    cd {{jetpack_home}}/system/bootstrap/azure-slurm-install
    ./install.sh --mode scheduler --bootstrap-config {{jetpack_home}}/config/node.json
  args: 
    executable: /bin/bash
    creates: '/etc/azslurm-bins.installed' 

# Install autoscaling for slurm. 
# For reference see https://github.com/Azure/cyclecloud-slurm/blob/master/specs/scheduler/cluster-init/scripts/00-install.sh
- name: Download and extract {{autoscale_pkg}}
  unarchive:
    src: https://github.com/Azure/cyclecloud-slurm/releases/download/{{cyclecloud_slurm_release}}/{{autoscale_pkg}}
    dest: '{{jetpack_home}}/system/bootstrap'
    remote_src: yes
  args: 
    creates: '{{jetpack_home}}/system/bootstrap/{{autoscale_pkg}}'

- name: install azure-slurm
  shell: |
    cd {{jetpack_home}}/system/bootstrap/azure-slurm
    source ~/.bash_profile
    set -e
    export PATH=$PATH:/opt/cycle/jetpack/bin
    ./install.sh &> install.log
  args: 
    executable: /bin/bash

- name: create slurm extension config
  template:
    src: azhop.conf.j2
    dest: '/sched/{{ slurm_cluster_name }}/azhop.conf'
    owner: slurm
    group: slurm

- name: Include the azhop.conf in slurm.conf
  lineinfile:
    path: /etc/slurm/slurm.conf
    line: 'Include /sched/{{ slurm_cluster_name }}/azhop.conf'
    state: present

- name: create slurm prolog
  template:
    src: templates/prolog.sh.j2
    dest: /sched/{{ slurm_cluster_name }}/prolog.sh
    owner: slurm
    group: slurm
    mode: 0755

- name: create slurm epilog
  template:
    src: templates/epilog.sh.j2
    dest: /sched/{{ slurm_cluster_name }}/epilog.sh
    owner: slurm
    group: slurm
    mode: 0755

- name: configuration for accounting
  block:
    # workaround for bug https://github.com/Azure/cyclecloud-slurm/issues/215
    - name: Set the scheduler name in the accounting configuration file when accounting is enabled
      replace:
        path: /sched/{{ slurm_cluster_name }}/accounting.conf
        regexp: 'AccountingStorageHost.*'
        replace: 'AccountingStorageHost={{ scheduler.name | default("scheduler") }}' 

  when: accounting_enabled | default(false)

# Fixing https://github.com/Azure/cyclecloud-slurm/issues/221
- name: Install libmysqlclient-dev
  package:
    name: libmysqlclient-dev
    state: present
  when: ansible_distribution == 'Ubuntu'

# Start service. 
# For reference see https://github.com/Azure/cyclecloud-slurm/blob/master/specs/scheduler/cluster-init/scripts/00-install.sh
- name: start service
  shell: |
    set -e
    {{jetpack_home}}/system/bootstrap/azure-slurm-install/start-services.sh scheduler
  retries: 5
  delay: 10
  register: result
  until: result.rc == 0

- name: ensure munge is running.
  service:
    name: munge 
    state: restarted
    enabled: yes

# No longer needed
# - name: refresh slurm node list
#   shell: |
#     set -e
#     /root/bin/azslurm scale
#     ln -fs /sched/{{ slurm_cluster_name }}/gres.conf /etc/slurm/gres.conf && chown slurm:slurm /etc/slurm/gres.conf
